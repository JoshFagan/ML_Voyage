{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Extract-Features-and-Targets\" data-toc-modified-id=\"Extract-Features-and-Targets-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Extract Features and Targets</a></span></li><li><span><a href=\"#Create-Validation-Set\" data-toc-modified-id=\"Create-Validation-Set-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Create Validation Set</a></span></li><li><span><a href=\"#Explore-Data\" data-toc-modified-id=\"Explore-Data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Explore Data</a></span></li><li><span><a href=\"#Manage-Missing-Categorical-Data\" data-toc-modified-id=\"Manage-Missing-Categorical-Data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Manage Missing Categorical Data</a></span></li><li><span><a href=\"#Drop-Features-with-Missing-Data\" data-toc-modified-id=\"Drop-Features-with-Missing-Data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Drop Features with Missing Data</a></span></li><li><span><a href=\"#Imputation\" data-toc-modified-id=\"Imputation-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Imputation</a></span></li><li><span><a href=\"#Mixed-Dropping-and-Imputation\" data-toc-modified-id=\"Mixed-Dropping-and-Imputation-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Mixed Dropping and Imputation</a></span></li><li><span><a href=\"#Scikit-Learn-Built-In-Imputer\" data-toc-modified-id=\"Scikit-Learn-Built-In-Imputer-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Scikit Learn Built In Imputer</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data locations\n",
    "data_dir        = '../Data/house-prices-advanced-regression-techniques/'\n",
    "train_file_name = 'train.csv'\n",
    "test_file_name  = 'test.csv'\n",
    "\n",
    "# Load training and testing data\n",
    "train_data = pd.read_csv( data_dir + train_file_name, index_col='Id' )\n",
    "test_data  = pd.read_csv( data_dir + test_file_name, index_col='Id' )\n",
    "\n",
    "# Remove rows with missing targets\n",
    "train_data.dropna( axis=0, subset=['SalePrice'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract targets and features\n",
    "y = train_data.SalePrice\n",
    "X = train_data.copy()\n",
    "X.drop( ['SalePrice'], axis=1, inplace=True )\n",
    "\n",
    "# As instructed by course, use only numerical data\n",
    "# Update: Include categorical data\n",
    "# Uncomment if categorical data no longer wanted\n",
    "#X = X.select_dtypes( exclude=['object'] )\n",
    "#X_test = test_data.select_dtypes( exclude=['object'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split( X, y, \n",
    "                                                   train_size=0.8, \n",
    "                                                   test_size=0.2, \n",
    "                                                   random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save space from extraneous output, uncomment command of interst when desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.describe()\n",
    "#X_train.head()\n",
    "#y_train.describe()\n",
    "#y_train.head()\n",
    "\n",
    "#X_test.describe()\n",
    "#X_test.head()\n",
    "#list(X_test.columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defined via the specs on the Kaggle course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A system being the combination of model and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_system( m=model, X_t=X_train, X_v=X_val, y_t=y_train, y_v=y_val ):\n",
    "    m.fit( X_t, y_t )\n",
    "    pred_val = m.predict( X_v )\n",
    "    return mean_absolute_error( pred_val, y_v )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 79)\n",
      "LotFrontage      212\n",
      "Alley           1097\n",
      "MasVnrType         6\n",
      "MasVnrArea         6\n",
      "BsmtQual          28\n",
      "BsmtCond          28\n",
      "BsmtExposure      28\n",
      "BsmtFinType1      28\n",
      "BsmtFinType2      29\n",
      "Electrical         1\n",
      "FireplaceQu      551\n",
      "GarageType        58\n",
      "GarageYrBlt       58\n",
      "GarageFinish      58\n",
      "GarageQual        58\n",
      "GarageCond        58\n",
      "PoolQC          1164\n",
      "Fence            954\n",
      "MiscFeature     1119\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Shape of training data (num_data_points, num_features)\n",
    "print( X_train.shape )\n",
    "\n",
    "# Number of missing values for each feature of training data\n",
    "num_missing_val_per_feature = X_train.isnull().sum()\n",
    "print( num_missing_val_per_feature[num_missing_val_per_feature > 0] )\n",
    "\n",
    "# Features with missing values\n",
    "feats_missing_vals = list(X_train.columns[X_train.isnull().any()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage Missing Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alley', 'MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Electrical', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n"
     ]
    }
   ],
   "source": [
    "# Get the columns for categorical features that are missing values\n",
    "num_missing_val_per_categorical = X_train.select_dtypes( 'object' ).isnull().sum()\n",
    "num_missing_val_per_categorical = num_missing_val_per_categorical[num_missing_val_per_categorical > 0]\n",
    "missing_val_categorical_cols = list(X_train.columns[(X_train.dtypes =='object') & X_train.isnull().any()])\n",
    "print( missing_val_categorical_cols )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the provided description, most of the missing values should be replaced with \"NA\"\n",
    "\n",
    "The only special cases are:\n",
    " \n",
    "MasVnrType: Masonry veneer type\n",
    "- None: None\n",
    "\n",
    "BsmtExposure: Refers to walkout or garden level walls\n",
    "- No:   No Exposure\n",
    "- NA:   No Basement\n",
    "\n",
    "Electrical: Electrical system\n",
    "- No good label, suggest removing data points or feature instead. Decision will be made based on number of data points missing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Features with Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_X_train    = X_train.drop( feats_missing_vals, axis=1, inplace=False )\n",
    "reduced_X_val      = X_val.drop( feats_missing_vals, axis=1, inplace=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop feats with missing data MAE: 17837.83\n"
     ]
    }
   ],
   "source": [
    "print( 'Drop feats with missing data MAE: %.2f' % \n",
    "       score_system( X_t=reduced_X_train, X_v=reduced_X_val ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_imputation( replacement, X_t=X_train, X_v=X_val ):\n",
    "    # Impute missing values with specified replacement\n",
    "    imputed_X_train = X_t.fillna( replacement )\n",
    "    imputed_X_val   = X_v.fillna( replacement )\n",
    "    return score_system( X_t=imputed_X_train, X_v=imputed_X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean imputation MAE: 18062.89\n",
      "Median imputation MAE: 17791.60\n",
      "Min imputation MAE: 18079.88\n",
      "Scalar (0) imputation MAE: 18017.67\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean for each feature with missing values\n",
    "feat_means   = X_train[feats_missing_vals].mean( skipna=True )\n",
    "feat_medians = X_train[feats_missing_vals].median( skipna=True )\n",
    "feat_mins    = X_train[feats_missing_vals].min( skipna=True )\n",
    "\n",
    "print( 'Mean imputation MAE: %.2f' % score_imputation( feat_means ) )\n",
    "print( 'Median imputation MAE: %.2f' % score_imputation( feat_medians ) )\n",
    "print( 'Min imputation MAE: %.2f' % score_imputation( feat_mins ) )\n",
    "print( 'Scalar (0) imputation MAE: %.2f' % score_imputation( 0 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed Dropping and Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the feature descriptions gives rise to intuition about whether removing the feature or imputation of the feature makes sense.\n",
    "\n",
    "LotFrontage - Linear feet of street connected to property  \n",
    "- Likely missing if no street is connected to property such as an apartment or condo.  \n",
    "- If this is the case, it makes sense to use imputation with 0's to fill for NAN\n",
    "\n",
    "MasVnrArea  - Masonry veneer area in square feet  \n",
    "- Likely missing if no masonry veneer  \n",
    "- If this is the case, it makes sense to use imputation with 0's to fill for NAN\n",
    "\n",
    "GarageYrBlt - Year garage was built  \n",
    "- Likely missing if no garage  \n",
    "- If this is the case, imputation does not make much sense and simply removing the feature may result in better calssification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed dropping and scalar (0) imputation MAE: 18133.38\n"
     ]
    }
   ],
   "source": [
    "# Drop year garage was built\n",
    "reduced_X_train    = X_train.drop( ['GarageYrBlt'], axis=1, inplace=False )\n",
    "reduced_X_val      = X_val.drop( ['GarageYrBlt'], axis=1, inplace=False )\n",
    "\n",
    "# Perform scalar imputation with 0's\n",
    "print( 'Mixed dropping and scalar (0) imputation MAE: %.2f' % \n",
    "       score_imputation( 0, X_t=reduced_X_train, X_v=reduced_X_val ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit Learn Built In Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A less \"reinventing the wheel\" heavy method is to use Scikit Learn's built in simple imputer class.\n",
    "\n",
    "I think I like the way I performed Imputation above better. There is less code involved and it seems to be simpler operations. It also has the benefit of working natively with Panda's Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean imputation with Scikit Learn MAE: 17791.60\n"
     ]
    }
   ],
   "source": [
    "imputed_X_train = X_train.copy()\n",
    "imputed_X_val   = X_val.copy()\n",
    "median_imputer  = SimpleImputer( strategy='median' )\n",
    "\n",
    "imputed_X_train = pd.DataFrame( median_imputer.fit_transform(imputed_X_train) )\n",
    "imputed_X_val   = pd.DataFrame( median_imputer.transform(imputed_X_val) )\n",
    "\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_val.columns = X_val.columns\n",
    "imputed_X_train.head()\n",
    "score_system( X_t=imputed_X_train, X_v=imputed_X_val)\n",
    "print( 'Mean imputation with Scikit Learn MAE: %.2f' % \n",
    "       score_system( X_t=imputed_X_train, X_v=imputed_X_val) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
