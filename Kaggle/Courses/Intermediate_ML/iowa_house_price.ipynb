{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Extract-Features-and-Targets\" data-toc-modified-id=\"Extract-Features-and-Targets-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Extract Features and Targets</a></span></li><li><span><a href=\"#Create-Validation-Set\" data-toc-modified-id=\"Create-Validation-Set-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Create Validation Set</a></span></li><li><span><a href=\"#Explore-Data\" data-toc-modified-id=\"Explore-Data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Explore Data</a></span></li><li><span><a href=\"#Manage-Missing-Categorical-Data\" data-toc-modified-id=\"Manage-Missing-Categorical-Data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Manage Missing Categorical Data</a></span></li><li><span><a href=\"#Manage-Missing-Numerical-Data\" data-toc-modified-id=\"Manage-Missing-Numerical-Data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Manage Missing Numerical Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Drop-Numerical-Features-with-Missing-Data\" data-toc-modified-id=\"Drop-Numerical-Features-with-Missing-Data-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Drop Numerical Features with Missing Data</a></span></li><li><span><a href=\"#Imputation\" data-toc-modified-id=\"Imputation-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Imputation</a></span></li><li><span><a href=\"#Mixed-Dropping-and-Imputation\" data-toc-modified-id=\"Mixed-Dropping-and-Imputation-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Mixed Dropping and Imputation</a></span></li></ul></li><li><span><a href=\"#Drop-Categorical-Data\" data-toc-modified-id=\"Drop-Categorical-Data-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Drop Categorical Data</a></span></li><li><span><a href=\"#Label-Encode-Categorical-Data\" data-toc-modified-id=\"Label-Encode-Categorical-Data-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Label Encode Categorical Data</a></span></li><li><span><a href=\"#One-Hot-Encode-Categorical-Data\" data-toc-modified-id=\"One-Hot-Encode-Categorical-Data-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>One-Hot Encode Categorical Data</a></span></li><li><span><a href=\"#Join-Training-and-Validation\" data-toc-modified-id=\"Join-Training-and-Validation-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Join Training and Validation</a></span></li><li><span><a href=\"#Create-Pipeline-with-Winning-Transformation-Combo\" data-toc-modified-id=\"Create-Pipeline-with-Winning-Transformation-Combo-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Create Pipeline with Winning Transformation Combo</a></span></li><li><span><a href=\"#Fit-Pipeline-to-Data-and-Make-Predictions\" data-toc-modified-id=\"Fit-Pipeline-to-Data-and-Make-Predictions-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Fit Pipeline to Data and Make Predictions</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data locations\n",
    "data_dir        = '../Data/house-prices-advanced-regression-techniques/'\n",
    "train_file_name = 'train.csv'\n",
    "test_file_name  = 'test.csv'\n",
    "\n",
    "# Load training and testing data\n",
    "train_data = pd.read_csv( data_dir + train_file_name, index_col='Id' )\n",
    "test_data  = pd.read_csv( data_dir + test_file_name, index_col='Id' )\n",
    "\n",
    "# Rearrange columns alphabetically \n",
    "train_data = train_data.reindex(sorted(train_data.columns), axis=1)\n",
    "test_data = test_data.reindex(sorted(test_data.columns), axis=1)\n",
    "\n",
    "# Remove rows with missing targets\n",
    "train_data.dropna( axis=0, subset=['SalePrice'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract targets and features\n",
    "y = train_data.SalePrice\n",
    "X = train_data.copy()\n",
    "X.drop( ['SalePrice'], axis=1, inplace=True )\n",
    "\n",
    "X_test = test_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not needed if we are using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split( X, y, \n",
    "                                                   train_size=0.8, \n",
    "                                                   test_size=0.2, \n",
    "                                                   random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.ProfileReport( X )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage Missing Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alley', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', 'Electrical', 'Fence', 'FireplaceQu', 'GarageCond', 'GarageFinish', 'GarageQual', 'GarageType', 'MasVnrType', 'MiscFeature', 'PoolQC']\n"
     ]
    }
   ],
   "source": [
    "# Get the columns for categorical features that are missing values\n",
    "cat_feats_missing_vals = list(X.columns[(X.dtypes =='object') & X.isnull().any()])\n",
    "print( cat_feats_missing_vals )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the provided description, most of the missing values should be replaced with \"NA\"\n",
    "\n",
    "The only special cases are:\n",
    " \n",
    "MasVnrType: Masonry veneer type\n",
    "- None: None\n",
    "\n",
    "BsmtExposure: Refers to walkout or garden level walls\n",
    "- No:   No Exposure\n",
    "- NA:   No Basement\n",
    "\n",
    "Electrical: Electrical system\n",
    "- No good label, as such we will remove this featue. Additionaly, from the Profile Report we see this feature has a uniqueness of 0.4% so this feature may not tell us much about the data anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Possible reasons for missing values on BsmtExposure could be \"no exposure\" or \"no basement\"\n",
    "# We can do a simple crossreference to see how many times values exist in other basement categories and not for BsmtExposure\n",
    "(X['BsmtExposure'].isnull() & X['BsmtCond'].notnull()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This occurs once so to be safe we can map NaN to No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Transformer that maps missing categoical labels to their appropriate label\n",
    "class CustomCategoicalImputer( BaseEstimator, TransformerMixin ):\n",
    "    #Class Constructor \n",
    "    def __init__( self ):\n",
    "        self._label_mapping = {}\n",
    "        \n",
    "    def fit( self, X, y=None ):\n",
    "        feats_missing_vals = list(X.columns[X.isnull().any()])\n",
    "        \n",
    "        for feat in feats_missing_vals:\n",
    "            self._label_mapping[feat] = 'NA'\n",
    "        \n",
    "        self._label_mapping['MasVnrType'] = 'None'\n",
    "        self._label_mapping['BsmtExposure'] = 'No'\n",
    "\n",
    "\n",
    "        return self \n",
    "    \n",
    "    def transform( self, X, y=None ):\n",
    "        X.drop( columns=['Electrical'], inplace=True )\n",
    "        X.fillna( value=self._label_mapping, inplace=True )\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_impute_categorical_pipe_tuple = ('custom_impute_categorical',\n",
    "                                        CustomCategoicalImputer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation should be done on all columns in case features are missing values in the test set and not the training set. Some features however do not have a good default value we can infer from their description. Because of this we will do \"Most Frequent\" imputation on all of the columns after performing the custom imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_impute_categorical_pipe_tuple = ('most_frequent_impute_categorical',\n",
    "                                               SimpleImputer(strategy='most_frequent'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage Missing Numerical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Numerical Features with Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping feats with missing values is as simple as not including those columns in the ColumnTranformation pipeline. \n",
    "\n",
    "We should perform some sort of imputation afterwards in the event a feature is missing a value in the test set and not in the training set. \n",
    "\n",
    "As such we can just perform imputation on the columns with no missing values in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feats              = X.columns[X.dtypes != 'object']\n",
    "numerical_feats_missing_vals = X.columns[(X.dtypes != 'object') & X.isna().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_missing_numerical_trans_tuple = ('drop_missing_numerical', \n",
    "                                      SimpleImputer(strategy='median'), \n",
    "                                      numerical_feats.difference(numerical_feats_missing_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation can be done with the \"SimpleImputer\" class transforming all of the numerical columns.\n",
    "\n",
    "The example below uses median imputation but any form can be used by defining a new tranformation tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feats = X.columns[X.dtypes != 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_missing_numerical_trans_tuple = ('impute_missing_numerical', \n",
    "                                        SimpleImputer(strategy='median'), \n",
    "                                        numerical_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed Dropping and Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the feature descriptions gives rise to intuition about whether removing the feature or imputation of the feature makes sense.\n",
    "\n",
    "LotFrontage - Linear feet of street connected to property  \n",
    "- Likely missing if no street is connected to property such as an apartment or condo.  \n",
    "- If this is the case, it makes sense to use imputation with 0's to fill for NAN\n",
    "\n",
    "MasVnrArea  - Masonry veneer area in square feet  \n",
    "- Likely missing if no masonry veneer  \n",
    "- If this is the case, it makes sense to use imputation with 0's to fill for NAN\n",
    "\n",
    "GarageYrBlt - Year garage was built  \n",
    "- Likely missing if no garage  \n",
    "- If this is the case, imputation does not make much sense and simply removing the feature may result in better calssification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixing dropping and imputing features again is as simple as just not including the offending columns in the ColumnTransformation pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feats         = X.columns[X.dtypes != 'object']\n",
    "numerical_feats_to_drop = ['GarageYrBlt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_drop_impute_missing_numerical_trans_tuple = ('mixed_drop_impute_missing_numerical', \n",
    "                                                   SimpleImputer(strategy='median'), \n",
    "                                                   numerical_feats.difference(numerical_feats_to_drop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping categorical data is as simple as not including a tuple for categorical data in the ColumnTransformer pipeline. A transformation tuple is defined below in order to help automate the process of comparing all pipeline methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feats = X.columns[X.dtypes == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_categorical_trans_tuple = ('drop_categorical', 'drop', categorical_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encode Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard label encoder does not have a way of encoding labels found in the test set that are not in the training set. \n",
    "\n",
    "For this reason we write our own that assigns the encoding 0 to any label in the test set that does not appear in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Transformer that maps missing categoical labels to their appropriate label\n",
    "class CustomCategoicalLabelEncoder( BaseEstimator, TransformerMixin ):\n",
    "    #Class Constructor \n",
    "    def __init__( self ):\n",
    "        self._label_map = {}\n",
    "        \n",
    "    def fit( self, X, y=None ):        \n",
    "        for feat in X.columns:\n",
    "            unique_dict   = defaultdict(lambda: 0)\n",
    "            unique_values = X[feat].unique()\n",
    "            for i in range(len(unique_values)):\n",
    "                unique_dict[unique_values[i]] = i+1\n",
    "    \n",
    "            self._label_map[feat] = unique_dict\n",
    "\n",
    "        return self \n",
    "    \n",
    "    def transform( self, X, y=None ):\n",
    "        for feat in X.columns:\n",
    "            X[feat] = X[feat].map( self._label_map[feat] )\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feats = X.columns[X.dtypes == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_label_categorical_pipe_tuple  = ('custom_label_categorical',\n",
    "                                        CustomCategoicalLabelEncoder())\n",
    "\n",
    "custom_label_categorical_pipeline    = Pipeline( steps=[custom_impute_categorical_pipe_tuple,\n",
    "                                                        custom_label_categorical_pipe_tuple,\n",
    "                                                        most_frequent_impute_categorical_pipe_tuple] )\n",
    "\n",
    "custom_label_categorical_trans_tuple = ('custom_label_categorical',\n",
    "                                        custom_label_categorical_pipeline,\n",
    "                                        categorical_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encode Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform One-Hot encoding on the data specifying cardinality thresholds using the sklearn OneHotEncoder and passing only columns that have a low enough cardinality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_thresh = 10\n",
    "categorical_feats  = X.columns[X.dtypes == 'object']\n",
    "low_card_cat_feats = [feat for feat in categorical_feats if X[feat].nunique() <= card_thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_categorical_pipe_tuple  = ('one_hot_categorical',\n",
    "                                   OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "\n",
    "one_hot_categorical_pipeline    = Pipeline( steps=[custom_impute_categorical_pipe_tuple,\n",
    "                                                   most_frequent_impute_categorical_pipe_tuple,\n",
    "                                                   one_hot_categorical_pipe_tuple] )\n",
    "\n",
    "one_hot_categorical_trans_tuple = ('one_hot_categorical',\n",
    "                                   one_hot_categorical_pipeline,\n",
    "                                   low_card_cat_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defined via the specs on the Kaggle course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A system being the combination of model and dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score system function not needed if doing cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_system( pipeline, X_t=X_train, X_v=X_val, y_t=y_train, y_v=y_val ):\n",
    "    pipeline.fit( X_t, y_t )\n",
    "    pred_val = pipeline.predict( X_v )\n",
    "    return mean_absolute_error( pred_val, y_v )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_transformation_combinations( cat_trans, num_trans, m=model ):\n",
    "    for num_transform in num_trans:\n",
    "        print( 'MAE with %s:' % (num_transform) )\n",
    "        for cat_transform in cat_trans:\n",
    "            preprocessor = ColumnTransformer( transformers=[num_trans[num_transform],\n",
    "                                                            cat_trans[cat_transform]] )\n",
    "            pipeline = Pipeline( steps=[('preprocessor', preprocessor),\n",
    "                                        ('model', m)] )\n",
    "            \n",
    "            scores = -1 * cross_val_score( pipeline, X, y, cv=5,\n",
    "                                           scoring='neg_mean_absolute_error')\n",
    "            \n",
    "            print( \"\\tAverage MAE score (across experiments) with %s: %f\" % (cat_transform, scores.mean()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset slices to ensure transformations work\n",
    "card_thresh = 10\n",
    "categorical_feats  = X.columns[X.dtypes == 'object']\n",
    "low_card_cat_feats = [feat for feat in categorical_feats if X[feat].nunique() <= card_thresh]\n",
    "\n",
    "numerical_feats              = X.columns[X.dtypes != 'object']\n",
    "numerical_feats_missing_vals = X.columns[(X.dtypes != 'object') & X.isna().any()]\n",
    "numerical_feats_to_drop      = ['GarageYrBlt'] # Feats to drop during mixed dropping and imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformations = {'drop_categorical'         : drop_categorical_trans_tuple,\n",
    "                               'custom_label_categorical' : custom_label_categorical_trans_tuple,\n",
    "                               'one_hot_categorical'      : one_hot_categorical_trans_tuple}\n",
    "\n",
    "numerical_transformations   = {'drop_missing_numerical'              : drop_missing_numerical_trans_tuple,\n",
    "                               'impute_missing_numerical'            : impute_missing_numerical_trans_tuple,\n",
    "                               'mixed_drop_impute_missing_numerical' : mixed_drop_impute_missing_numerical_trans_tuple}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE with drop_missing_numerical:\n",
      "\tAverage MAE score (across experiments) with drop_categorical: 17884.688402\n",
      "\tAverage MAE score (across experiments) with custom_label_categorical: 17575.180740\n",
      "\tAverage MAE score (across experiments) with one_hot_categorical: 17656.401849\n",
      "MAE with impute_missing_numerical:\n",
      "\tAverage MAE score (across experiments) with drop_categorical: 18053.033783\n",
      "\tAverage MAE score (across experiments) with custom_label_categorical: 17662.064911\n",
      "\tAverage MAE score (across experiments) with one_hot_categorical: 17720.302932\n",
      "MAE with mixed_drop_impute_missing_numerical:\n",
      "\tAverage MAE score (across experiments) with drop_categorical: 17989.217826\n",
      "\tAverage MAE score (across experiments) with custom_label_categorical: 17614.623589\n",
      "\tAverage MAE score (across experiments) with one_hot_categorical: 17665.810514\n"
     ]
    }
   ],
   "source": [
    "evaluate_transformation_combinations( categorical_transformations,\n",
    "                                      numerical_transformations )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to use the most data on hand to produce the best model possible for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset slices to ensure transformations work\n",
    "card_thresh = 10\n",
    "categorical_feats  = X.columns[X.dtypes == 'object']\n",
    "low_card_cat_feats = [feat for feat in categorical_feats if X[feat].nunique() <= card_thresh]\n",
    "\n",
    "numerical_feats              = X.columns[X.dtypes != 'object']\n",
    "numerical_feats_missing_vals = X.columns[(X.dtypes != 'object') & X.isna().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline with Winning Transformation Combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = ColumnTransformer( transformers=[numerical_transformations['drop_missing_numerical'],\n",
    "                                              categorical_transformations['custom_label_categorical']] )\n",
    "pipeline = Pipeline( steps=[('preprocess', preprocess), \n",
    "                            ('model', model)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit( X, y )\n",
    "\n",
    "preds_test = pipeline.predict( X_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Pipeline to Data and Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = range( 50, 450, 50 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
